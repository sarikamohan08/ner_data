import spacy
from spacy.training import Example
from spacy.tokens import DocBin
from spacy.training import Config, Trainer

# 1. Create and Annotate Training Data
def create_training_data():
    # Define the training data with "Patient Name:" prefix
    train_data = [
        ("Patient Name: John Doe, Member ID: 12345, SSN: 987-65-4321, Effective Date: 2022-01-01",
         {"entities": [(14, 22, "PATIENT_NAME"), (34, 39, "MEMBER_ID"), (44, 55, "SSN"), (71, 81, "EFFECTIVE_DATE")]}),
        ("Jane Smith, Member ID: 54321, SSN: 123-45-6789, Effective Date: 2023-02-15",
         {"entities": [(0, 10, "OTHER_NAME"), (22, 27, "MEMBER_ID"), (32, 43, "SSN"), (59, 69, "EFFECTIVE_DATE")]}),
        ("Patient Name: Emily Davis, SSN: 333-44-5555, Member ID: 101112, Effective Date: October 10, 2020",
         {"entities": [(14, 25, "PATIENT_NAME"), (31, 42, "SSN"), (55, 61, "MEMBER_ID"), (77, 93, "EFFECTIVE_DATE")]}),
        ("Member ID: 67890, SSN: 222-33-4444, Effective Date: 2021-05-20, Patient Name: Robert Johnson",
         {"entities": [(67, 81, "PATIENT_NAME"), (11, 16, "MEMBER_ID"), (21, 32, "SSN"), (48, 58, "EFFECTIVE_DATE")]}),
        ("Patient Name: Sarah Lee, SSN: 444-55-6666, Member ID: 131415, Effective Date: 31st December 2021",
         {"entities": [(14, 23, "PATIENT_NAME"), (30, 41, "SSN"), (54, 60, "MEMBER_ID"), (77, 96, "EFFECTIVE_DATE")]}),
        ("Effective Date: 2022/11/11, Member ID: 161718, Patient Name: Daniel Kim, SSN: 555-66-7777",
         {"entities": [(44, 54, "EFFECTIVE_DATE"), (67, 73, "MEMBER_ID"), (79, 89, "PATIENT_NAME"), (95, 106, "SSN")]}),
        ("Nancy Thompson, SSN: 999-00-1111, Member ID: 282930, Effective Date: 03.14.2022",
         {"entities": [(0, 15, "OTHER_NAME"), (21, 32, "SSN"), (46, 52, "MEMBER_ID"), (58, 68, "EFFECTIVE_DATE")]}),
        ("Patient Name: Elizabeth Rodriguez, Effective Date: 31/12/2016, Member ID: 343536, SSN: 212-22-2324",
         {"entities": [(14, 34, "PATIENT_NAME"), (50, 60, "EFFECTIVE_DATE"), (74, 80, "MEMBER_ID"), (86, 97, "SSN")]}),
        ("Kevin White, Effective Date: 19th July 2018, SSN: 888-99-0000, Member ID: 252627",
         {"entities": [(0, 11, "OTHER_NAME"), (28, 48, "EFFECTIVE_DATE"), (55, 66, "SSN"), (80, 86, "MEMBER_ID")]}),
        ("Patient Name: Jennifer Martinez, Member ID: 404142, SSN: 777-88-9999, Effective Date: 2023/04/25",
         {"entities": [(14, 32, "PATIENT_NAME"), (35, 41, "MEMBER_ID"), (47, 58, "SSN"), (64, 74, "EFFECTIVE_DATE")]}),
        ("Ashley Hernandez, SSN: 303-30-3132, Member ID: 585960, Effective Date: 2nd February 2022",
         {"entities": [(0, 16, "OTHER_NAME"), (22, 33, "SSN"), (47, 53, "MEMBER_ID"), (69, 87, "EFFECTIVE_DATE")]}),
        ("Patient Name: Megan Clark, SSN: 303-30-3132, Member ID: 585960, Effective Date: 2nd February 2022",
         {"entities": [(14, 26, "PATIENT_NAME"), (31, 42, "SSN"), (56, 62, "MEMBER_ID"), (78, 96, "EFFECTIVE_DATE")]}),
        ("Joshua Moore, Member ID: 495051, SSN: 272-27-2829, Effective Date: 2017-March-05",
         {"entities": [(0, 12, "OTHER_NAME"), (24, 30, "MEMBER_ID"), (35, 46, "SSN"), (62, 76, "EFFECTIVE_DATE")]}),
        ("Karen Lee, Effective Date: 25-11-2024, Member ID: 555657, SSN: 292-29-3031",
         {"entities": [(0, 9, "OTHER_NAME"), (27, 37, "EFFECTIVE_DATE"), (51, 57, "MEMBER_ID"), (63, 74, "SSN")]}),
        ("Patient Name: Luis Garcia, SSN: 404-40-4040, Effective Date: 01/01/2024, Member ID: 666768",
         {"entities": [(14, 25, "PATIENT_NAME"), (30, 41, "SSN"), (57, 67, "EFFECTIVE_DATE"), (72, 78, "MEMBER_ID")]}),
        ("Jessica Wilson, SSN: 212-21-2121, Effective Date: 2024-01-15, Member ID: 787980",
         {"entities": [(0, 14, "OTHER_NAME"), (17, 28, "SSN"), (34, 44, "EFFECTIVE_DATE"), (49, 55, "MEMBER_ID")]}),
        ("Michael Brown, Effective Date: 2023/11/15, Member ID: 919293, SSN: 808-99-0000",
         {"entities": [(0, 13, "OTHER_NAME"), (27, 37, "EFFECTIVE_DATE"), (44, 50, "MEMBER_ID"), (56, 67, "SSN")]}),
    ]

    # Create a blank spaCy model
    nlp = spacy.blank("en")

    # Add the NER pipeline component
    ner = nlp.add_pipe("ner")

    # Add labels to the NER component
    ner.add_label("PATIENT_NAME")
    ner.add_label("MEMBER_ID")
    ner.add_label("SSN")
    ner.add_label("EFFECTIVE_DATE")
    ner.add_label("OTHER_NAME")

    # Convert training data to spaCy's DocBin format
    doc_bin = DocBin()
    for text, annotations in train_data:
        doc = nlp.make_doc(text)
        example = Example.from_dict(doc, annotations)
        doc_bin.add(example.reference)

    # Save the DocBin file
    doc_bin.to_disk("./train.spacy")

# 2. Train the spaCy Model
def train_model():
    # Load the blank model
    nlp = spacy.load("en_core_web_sm")  # You can use a smaller or blank model as a base

    # Load the training data
    doc_bin = DocBin().from_disk("./train.spacy")
    train_data = list(doc_bin.get_docs(nlp.vocab))

    # Initialize the training configuration
    config = Config().from_str("""
    [train]
    epochs = 30
    batch_size = 8
    """)

    # Initialize the Trainer
    trainer = Trainer(nlp, config=config)

    # Add the NER component to the pipeline if not already present
    if "ner" not in nlp.pipe_names:
        nlp.add_pipe("ner")

    # Begin training
    trainer.begin_training()
    for epoch in range(30):
        losses = {}
        trainer.update(train_data, drop=0.5, losses=losses)
        print(f"Epoch {epoch} - Losses: {losses}")

    # Save the trained model
    nlp.to_disk("./custom_ner_model")

# 3. Implement Custom Extraction Logic
def extract_patient_name(text):
    nlp = spacy.load("./custom_ner_model")
    doc = nlp(text)
    patient_name = None
    for ent in doc.ents:
        if ent.label_ == "PATIENT_NAME":
            # Check if the entity is preceded by "Patient Name:"
            start_idx = ent.start_char
            if text[max(0, start_idx-14):start_idx].lower().startswith("patient name:"):
                patient_name = ent.text
                break
    return patient_name

# Run the entire workflow
if __name__ == "__main__":
    # Step 1: Create and Annotate Training Data
    create_training_data()
    
    # Step 2: Train the spaCy Model
    train_model()
    
    # Step 3: Use the trained model for extraction
    text1 = "Patient Name: Michael Johnson, Member ID: 98765, SSN: 111-22-3333, Effective Date: 2024-07-31"
    print("Extracted Patient Name:", extract_patient_name(text1))

    text2 = "Michael Johnson, Member ID: 98765, SSN: 111-22-3333, Effective Date: 2024-07-31"
    print("Extracted Patient Name:", extract_patient_name(text2))



from transformers import BertTokenizer, BertModel
tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')
model = BertModel.from_pretrained("bert-large-uncased")
text = "Replace me by any text you'd like."
encoded_input = tokenizer(text, return_tensors='pt')
output = model(**encoded_input)





import os
import ssl
from transformers import BertTokenizer, BertForTokenClassification
import torch

# Handle SSL certificate issues (use with caution)
os.environ['CURL_CA_BUNDLE'] = ''
ssl._create_default_https_context = ssl._create_unverified_context

# Load tokenizer and model
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
model = BertForTokenClassification.from_pretrained('bert-base-uncased')

# Example input text
text = "BERT is a powerful language model developed by Google."

# Tokenize input
inputs = tokenizer(text, return_tensors="pt")

# Get predictions
outputs = model(**inputs)
logits = outputs.logits

# Print results
print("Input Tokens:", tokenizer.convert_ids_to_tokens(inputs["input_ids"][0]))
print("Logits:", logits)

