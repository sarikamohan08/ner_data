"""
Requirements:
  pip install openai pydantic pandas

Set your OpenAI API key in the environment:
  export OPENAI_API_KEY="sk-..."

Usage:
  python extract_contracts_no_langchain.py
"""

import os
import json
import time
from typing import List, Optional
from pydantic import BaseModel, ValidationError
import pandas as pd

# Use the new OpenAI Python client if available; fallback to `openai` package style if needed.
try:
    # New (recommended) client
    from openai import OpenAI
    client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))
    def chat_completion_call(messages, model="gpt-4", temperature=0.0, max_tokens=4000):
        return client.chat.completions.create(model=model, messages=messages, temperature=temperature, max_tokens=max_tokens)
except Exception:
    # Fallback to legacy openai package
    import openai
    openai.api_key = os.environ.get("OPENAI_API_KEY")
    def chat_completion_call(messages, model="gpt-4", temperature=0.0, max_tokens=4000):
        return openai.ChatCompletion.create(model=model, messages=messages, temperature=temperature, max_tokens=max_tokens)

# ---------------------------
# 1) Pydantic schema matching your target columns
# ---------------------------
class RowModel(BaseModel):
    FILE_NAME: Optional[str] = None
    FILE_EXTENSION: Optional[str] = None
    CIS_TYPE_DESCRIPTION: Optional[str] = None
    PROVIDER_NAME: Optional[str] = None
    NPI: Optional[str] = None
    TAX_ID: Optional[str] = None
    EFFECTIVE_FROM_DATE: Optional[str] = None
    EFFECTIVE_TO_DATE: Optional[str] = None
    LOB_IND: Optional[str] = None
    SERVICE_TYPE: Optional[str] = None
    SERVICE_DESC: Optional[str] = None
    SERVICES: Optional[str] = None
    AGE_GROUP: Optional[int] = None
    CODES: Optional[str] = None
    GROUPER: Optional[str] = None
    CASE_RATE: Optional[str] = None
    REVENUE_CD_IND: Optional[int] = None
    DRG_CD_IND: Optional[int] = None
    CPT_IND: Optional[int] = None
    HCPCS_IND: Optional[int] = None
    ICD_CD_IND: Optional[int] = None
    DIAGNOSIS_CD_IND: Optional[int] = None
    MODIFIER_CD_IND: Optional[int] = None
    GROUPER_IND: Optional[int] = None
    APC_IND: Optional[int] = None
    EXCLUSION_IND: Optional[int] = None
    MSR_IND: Optional[int] = None
    BILETRAL_PROCEDURE_IND: Optional[int] = None
    EXCLUDE_FROM_TRANSFER_IND: Optional[int] = None
    TRANSFER_CALCULATION: Optional[str] = None
    EXCLUDE_FROM_STOPLOSS_IND: Optional[int] = None
    REIMBURSEMENT_AMT: Optional[str] = None
    REIMBURSEMENT_RATE: Optional[str] = None
    REIMBURSEMENT_METHODOLOGY: Optional[str] = None
    METHOD_OF_PAYMENT: Optional[str] = None
    HEALTH_BENEFIT_PLANS: Optional[str] = None
    ADDITIONAL_NOTES: Optional[str] = None
    PROVIDER_SPECIALITY: Optional[int] = None
    OTHER_FLAT_FEE: Optional[int] = None
    SURG_FLAT_FEE: Optional[int] = None

# Helper - full list of keys for coverage/ordering
SCHEMA_KEYS = list(RowModel.__fields__.keys())

# ---------------------------
# 2) The prompt (your exact text) but instructing the model to return JSON only.
# We ask the model to return an array of objects (JSON) with keys matching the schema.
# ---------------------------
base_user_prompt = (
    "You are a healthcare data analyst trained to extract structured data from healthcare contracts, "
    "including provider participation agreements and covered service schedules. "
    "You will receive text that may include provider details, effective dates, reimbursement rules, and coding information.\n\n"

    "=== TASK INSTRUCTIONS ===\n"
    "Extract structured information and assign it into a list of dictionaries following the column names below.\n"
    "If multiple providers appear, only extract the first one. If multiple services are listed, include each as a new record.\n"
    "If a field is not found, set its value to null.\n\n"

    "=== COLUMN NAMES (TARGET SCHEMA) ===\n"
    f"{json.dumps(SCHEMA_KEYS, indent=2)}\n\n"

    "=== EXTRACTION LOGIC ===\n"
    "- PROVIDER_NAME: the DBA or legal provider name.\n"
    "- NPI: provider’s NPI (10-digit).\n"
    "- TAX_ID: federal tax ID or EIN.\n"
    "- EFFECTIVE_FROM_DATE / EFFECTIVE_TO_DATE: effective date range of the agreement.\n"
    "- LOB_IND: line(s) of business mentioned (Medicare, Medicaid, Commercial, etc.).\n"
    "- SERVICE_TYPE: classify as inpatient, outpatient, skilled nursing, etc.\n"
    "- SERVICE_DESC: service description, paragraph text, or context phrase.\n"
    "- SERVICES: list all service levels, types, or categories mentioned.\n"
    "- AGE_GROUP: 1 if ‘Age group’ is mentioned, else 0.\n"
    "- CODES: include all detected revenue, DRG, CPT, HCPCS, ICD, or modifier codes.\n"
    "- GROUPER: extract any groupers or DRG/APC grouping logic mentioned.\n"
    "- CASE_RATE: text describing any case rate structure (e.g., 3-day, 7-day, etc.).\n"
    "- REVENUE_CD_IND: 1 if revenue code is present, else 0.\n"
    "- DRG_CD_IND: 1 if DRG code is present, else 0.\n"
    "- CPT_IND: 1 if CPT code is present, else 0.\n"
    "- HCPCS_IND: 1 if HCPCS code is present, else 0.\n"
    "- ICD_CD_IND: 1 if ICD code is present, else 0.\n"
    "- DIAGNOSIS_CD_IND: 1 if diagnosis code is present, else 0.\n"
    "- MODIFIER_CD_IND: 1 if modifier code is present, else 0.\n"
    "- GROUPER_IND: 1 if the term ‘grouper’ appears, else 0.\n"
    "- APC_IND: 1 if ‘APC’ appears, else 0.\n"
    "- EXCLUSION_IND: 1 if exclusion conditions are mentioned, else 0.\n"
    "- MSR_IND: 1 if ‘Multiple Surgery Logic’ appears, else 0.\n"
    "- BILETRAL_PROCEDURE_IND: 1 if ‘bilateral procedures’ appears, else 0.\n"
    "- EXCLUDE_FROM_TRANSFER_IND: 1 if ‘transfer’ or similar exclusion rule appears, else 0.\n"
    "- TRANSFER_CALCULATION: extract any transfer-related formula or text.\n"
    "- EXCLUDE_FROM_STOPLOSS_IND: 1 if ‘stop loss threshold’ appears, else 0.\n"
    "- REIMBURSEMENT_AMT: extract numeric or currency reimbursement value.\n"
    "- REIMBURSEMENT_RATE: extract percentage reimbursement rate if available.\n"
    "- REIMBURSEMENT_METHODOLOGY: must be one of "
    "['Per Diem', 'Per procedure', 'Per visit', 'Per case', 'Percent of charge', "
    "'Medicare allowable amount', 'Fee schedule', 'Percent of line charge', 'POC'].\n"
    "- METHOD_OF_PAYMENT: payment code string exactly as in text (e.g., 'no1', 'po3').\n"
    "- HEALTH_BENEFIT_PLANS: extract plan names or benefit plan identifiers.\n"
    "- ADDITIONAL_NOTES: any extra notes relevant to the section.\n"
    "- PROVIDER_SPECIALITY: 1 if provider specialty is mentioned, else 0.\n"
    "- OTHER_FLAT_FEE: 1 if any ‘flat fee’ term is present, else 0.\n"
    "- SURG_FLAT_FEE: 1 if ‘flat surgical fee’ or similar appears, else 0.\n\n"

    "=== MOP CODE TABLE ===\n"
    "no1: allowed amount = contracted rate.\n"
    "no2: allowed amount = lesser of contracted rate or % of billed charges.\n"
    "po3: allowed amount = greater of contracted rate or % of billed charges.\n"
    "no4: allowed amount = greater of contracted rate or total billed charges.\n\n"

    "IMPORTANT:\n"
    "Return ONLY a JSON array of objects. Each object must include all keys from the schema above; if a value is not found, use null.\n"
    "Do NOT return any explanatory text or code fences. Example output (JSON):\n"
    '[{"FILE_NAME": null, "FILE_EXTENSION": null, "CIS_TYPE_DESCRIPTION": null, ...}, { ... }]\n'
)

# ---------------------------
# 3) Read the input document (replace path as needed)
# ---------------------------
INPUT_PATH = "input_document.txt"
with open(INPUT_PATH, "r", encoding="utf-8") as fh:
    document_text = fh.read()

# ---------------------------
# 4) Call the model, with simple retry logic
# ---------------------------
system_message = {"role": "system", "content": "You are a deterministic data extraction assistant. Always follow instructions exactly."}
user_message = {"role": "user", "content": base_user_prompt + "\n\nDOCUMENT:\n" + document_text}

max_attempts = 3
response_text = None
for attempt in range(1, max_attempts + 1):
    try:
        resp = chat_completion_call(model="gpt-4", messages=[system_message, user_message], temperature=0.0, max_tokens=8000)
        # adapt to response shape for both SDKs
        if isinstance(resp, dict) and "choices" in resp:
            content = resp["choices"][0]["message"]["content"]
        else:
            # new OpenAI client returns object-like with attributes
            content = resp.choices[0].message["content"]
        response_text = content.strip()
        break
    except Exception as e:
        print(f"LLM call failed (attempt {attempt}): {e}")
        if attempt < max_attempts:
            time.sleep(1 + attempt * 2)
        else:
            raise

# ---------------------------
# 5) Clean response: strip fences if model included them
# ---------------------------
def strip_code_fences(s: str) -> str:
    # strip ```json ... ``` or ``` ... ```
    if s.startswith("```"):
        lines = s.splitlines()
        # remove first and last fence lines if present
        if lines[-1].strip().startswith("```"):
            return "\n".join(lines[1:-1]).strip()
    return s

if response_text is None:
    raise RuntimeError("No response from LLM")

cleaned = strip_code_fences(response_text)

# ---------------------------
# 6) Parse JSON. Model should have returned an array (list) of objects.
# ---------------------------
parsed_json = None
try:
    parsed_json = json.loads(cleaned)
    # If the model by chance returned a dict with key 'combined_data', accept that too:
    if isinstance(parsed_json, dict) and "combined_data" in parsed_json:
        parsed_json = parsed_json["combined_data"]
    if not isinstance(parsed_json, list):
        raise ValueError("Model did not return a JSON array at top-level.")
except Exception as e:
    # Helpful debug info — but in production, consider fallback extraction path or retry with stricter instructions.
    print("Failed to parse JSON from model response. Raw response:")
    print(response_text[:2000])
    raise

# ---------------------------
# 7) Validate + normalize each item to ensure it has every schema key (None if missing)
# ---------------------------
validated_rows = []
errors = []
for idx, item in enumerate(parsed_json):
    if not isinstance(item, dict):
        errors.append((idx, "item not an object/dict"))
        continue
    # Ensure all keys exist; add missing keys with None
    row_with_all_keys = {k: item.get(k, None) for k in SCHEMA_KEYS}
    # For indicators that should be int (0/1), attempt coercion; leave as None if not parseable
    int_fields = [
        "AGE_GROUP", "REVENUE_CD_IND", "DRG_CD_IND", "CPT_IND", "HCPCS_IND", "ICD_CD_IND",
        "DIAGNOSIS_CD_IND", "MODIFIER_CD_IND", "GROUPER_IND", "APC_IND", "EXCLUSION_IND",
        "MSR_IND", "BILETRAL_PROCEDURE_IND", "EXCLUDE_FROM_TRANSFER_IND", "EXCLUDE_FROM_STOPLOSS_IND",
        "PROVIDER_SPECIALITY", "OTHER_FLAT_FEE", "SURG_FLAT_FEE"
    ]
    for f in int_fields:
        v = row_with_all_keys.get(f)
        if v is None:
            row_with_all_keys[f] = None
        else:
            try:
                # Some models return "1" or "0" strings; coerce
                row_with_all_keys[f] = int(v)
            except Exception:
                # leave as-is (will be validated by Pydantic)
                pass
    try:
        validated = RowModel.parse_obj(row_with_all_keys)
        validated_rows.append(validated)
    except ValidationError as ve:
        errors.append((idx, ve))

if errors:
    print("Some rows failed validation or normalization. Examples (first 5):")
    for ex in errors[:5]:
        print(ex)

# Final combined_data: list of dicts matching your schema (all keys present)
combined_data: List[dict] = [r.dict() for r in validated_rows]

# Print summary
print(f"Extracted {len(combined_data)} records.")
if combined_data:
    print("First record preview (keys shown):")
    print(list(combined_data[0].keys()))
    print("First record values (trimmed):")
    # show a trimmed view of values:
    preview = {k: (v if v is None or (isinstance(v, (int,str)) and len(str(v))<200) else str(v)[:200]+"...") for k,v in combined_data[0].items()}
    print(json.dumps(preview, indent=2))

# ---------------------------
# 8) OPTIONAL: convert to pandas DataFrame and / or write to Databricks / Spark
# If you're running inside Databricks, use 'spark' available in the notebook. Example:
#   df = pd.DataFrame(combined_data)
#   spark_df = spark.createDataFrame(df)
#   spark_df.write.mode("overwrite").saveAsTable("my_db.extracted_contracts")
# Or to write as Delta outside Databricks you'll need delta-spark setup.
# ---------------------------
df = pd.DataFrame(combined_data)
print("Pandas DataFrame shape:", df.shape)

# Optionally save locally as CSV for quick inspection
df.to_csv("extracted_contracts_preview.csv", index=False)
print("Wrote extracted_contracts_preview.csv")

# combined_data variable is now ready for downstream steps (Databricks write, DB insert, etc.)
