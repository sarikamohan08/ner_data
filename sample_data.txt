import pandas as pd

# Load the Excel file with multiple sheets
input_file = 'input_file.xlsx'  # Replace with your actual Excel file path
output_file = 'output_file.xlsx'

# Load all sheets from the Excel file into a dictionary of DataFrames
sheets = pd.read_excel(input_file, sheet_name=None, header=None)  # Load without headers to inspect the data

# Define exact keywords for standard columns (columns we want to exclude)
standard_column_keywords = [
    'Service Description', 
    'MS-DRG', 
    'Rev Code', 
    'ICD9/I CD10', 
    'CPT', 
    'Coding/Definition'
]

# Placeholder for transformed data
transformed_data = []

# Debugging: Track processing
print("Processing sheets...")

# Iterate through each sheet
for sheet_name, df in sheets.items():
    print(f"Processing sheet: {sheet_name}")
    
    # Check if the sheet is empty or contains only headers
    if df.isnull().all().all():
        print(f"Sheet '{sheet_name}' is completely empty, skipping.")
        continue
    
    # Print first few rows to understand the structure
    print(f"First few rows of the sheet:\n{df.head()}")
    
    # Assume that the actual header row is in the 2nd or 3rd row (adjust if necessary)
    # Manually set the header row index to the appropriate value if necessary
    header_row_index = 1  # Adjust if your header is elsewhere (0-based index)
    
    # Reload the sheet with the correct header row, skipping any leading empty rows
    try:
        df = pd.read_excel(input_file, sheet_name=sheet_name, header=header_row_index)
    except Exception as e:
        print(f"Error loading sheet {sheet_name}: {e}")
        continue  # Skip the current sheet if there's an error

    # After loading, ensure the column names are standardized by stripping extra spaces
    df.columns = df.columns.str.strip()

    # Check if the sheet actually has any valid data
    if df.empty:
        print(f"Sheet '{sheet_name}' has no data, skipping.")
        continue

    # Identify provider columns dynamically by excluding standard columns
    provider_columns = [
        col for col in df.columns
        if col not in standard_column_keywords
    ]
    
    print(f"Detected provider columns: {provider_columns}")
    
    # Process each sheet
    for index, row in df.iterrows():
        # Only process rows that have a valid 'Service Description'
        if pd.notna(row.get('Service Description')):
            # Debugging: Print row being processed
            print(f"Processing row {index}: {row.to_dict()}")
            
            # Split coding/def values and repeat rows
            coding_values = str(row.get('Coding/Definition', '')).split(' AND ')
            for coding_value in coding_values:
                for provider in provider_columns:
                    provider_value = row.get(provider, None)
                    # Add to the transformed data
                    transformed_data.append({
                        'Provider': provider,
                        'Service Description': row.get('Service Description'),
                        'MS-DRG': row.get('MS-DRG'),
                        'Rev Code': row.get('Rev Code'),
                        'ICD9/I CD10': row.get('ICD9/I CD10'),
                        'CPT': row.get('CPT'),
                        'Coding/Definition': coding_value.strip(),
                        'Billed Charges/Percent': provider_value
                    })

# Check if any transformed data exists and save it to Excel
if transformed_data:
    transformed_df = pd.DataFrame(transformed_data)
    # Save the transformed data to a new Excel file
    transformed_df.to_excel(output_file, index=False)
    print(f"Transformed data saved to {output_file}")
else:
    print("No data was transformed. Check input file for data issues.")
