# STEP 1: Install required libraries (run once)
# %pip install sentence-transformers PyPDF2 openpyxl

# STEP 2: Import libraries
from PyPDF2 import PdfReader
from sentence_transformers import SentenceTransformer
import pandas as pd
import uuid
from databricks.vector_search.client import VectorSearchClient
from pyspark.sql import SparkSession
from pyspark.sql.types import StructType, StructField, StringType, ArrayType, FloatType

# STEP 3: Extract text from PDF
pdf_path = "/dbfs/FileStore/my_docs/sample.pdf"  # Upload this file manually
reader = PdfReader(pdf_path)

# Extract text
texts = []
for page in reader.pages:
    content = page.extract_text()
    if content:
        texts.append(content)

# Chunk text (per paragraph)
chunks = [t.strip() for text in texts for t in text.split("\n\n") if (t := t.strip())]

# STEP 4: Embed each chunk using SentenceTransformer
model = SentenceTransformer("all-MiniLM-L6-v2")
embeddings = model.encode(chunks).tolist()
ids = [str(uuid.uuid4()) for _ in chunks]

# STEP 5: Create Spark DataFrame and store as Delta table
spark = SparkSession.builder.getOrCreate()

schema = StructType([
    StructField("id", StringType(), False),
    StructField("text", StringType(), False),
    StructField("embedding", ArrayType(FloatType()), False)
])

data = list(zip(ids, chunks, embeddings))
df = spark.createDataFrame(data, schema)

# Save to Unity Catalog or Hive metastore
table_name = "default.pdf_embeddings_mosaic"
df.write.mode("overwrite").saveAsTable(table_name)

# STEP 6: Create Mosaic AI Vector Search Index
vs_client = VectorSearchClient()

index_name = "default.pdf_index_mosaic"

# Only needs to be done once
vs_client.create_vector_index(
    index_name=index_name,
    source_table_name=table_name,
    embedding_column="embedding",
    id_column="id"
)

# STEP 7: Query definitions (Tax ID and NPI)
queries = {
    "tax_id": "extract the tax id",
    "npi": "extract npi"
}

# STEP 8: Search with Mosaic AI Vector Search
results_list = []

for field, query in queries.items():
    query_embedding = model.encode([query])[0].tolist()

    results = vs_client.similarity_search(
        index_name=index_name,
        query_vector=query_embedding,
        columns=["id", "text"],
        num_results=3  # You can increase for deeper search
    )

    top_result = results['result'][0]['text'] if results['result'] else "Not found"

    results_list.append({
        "field": field,
        "prompt": query,
        "matched_text": top_result
    })

# STEP 9: Save output to Excel
df_result = pd.DataFrame(results_list)
excel_path = "/dbfs/FileStore/my_docs/extracted_fields_mosaic.xlsx"
df_result.to_excel(excel_path, index=False)

print(f"âœ… Extracted fields saved to: {excel_path}")
