import os
import re
import json
import time
import openai
import pandas as pd
from typing import List, Dict, Any

# ================================================================
# CONFIG
# ================================================================
openai.api_key = os.getenv("OPENAI_API_KEY")
MODEL = "gpt-4o-mini"

CHUNK_SIZE = 3500
CHUNK_OVERLAP = 400
MAX_RETRIES = 3


# ================================================================
# PROMPT-A (MAIN EXTRACTION)
# ================================================================
PROMPT_A = """
<<< PLACE YOUR FULL PROMPT-A TEXT HERE >>>
"""


# ================================================================
# PROMPT-B (INDICATOR EXTRACTION)
# ================================================================
PROMPT_B = """
<<< PLACE YOUR FULL PROMPT-B TEXT HERE >>>
"""


# ================================================================
# CHUNK SPLITTER
# ================================================================
def split_text(text: str, size=CHUNK_SIZE, overlap=CHUNK_OVERLAP) -> List[str]:
    chunks = []
    start = 0

    while start < len(text):
        end = start + size
        chunk = text[start:end]
        chunks.append(chunk)
        start = max(0, end - overlap)

        if start >= len(text):
            break

    return chunks


# ================================================================
# CALL LLM WITH RETRIES
# ================================================================
def call_llm(prompt: str, chunk: str) -> List[Dict]:
    message = prompt + "\n\nTEXT:\n" + chunk

    for attempt in range(MAX_RETRIES):
        try:
            resp = openai.ChatCompletion.create(
                model=MODEL,
                messages=[{"role": "user", "content": message}],
                temperature=0,
                max_tokens=1200
            )

            content = resp.choices[0].message.content.strip()

            if content.startswith("```"):
                content = content.replace("```json", "").replace("```", "").strip()

            return json.loads(content)

        except Exception as e:
            print(f"Retry {attempt+1} for LLM… Error:", str(e))
            time.sleep(1)

    print("LLM failed after retries.")
    return []


# ================================================================
# MERGE A + B RESULTS
# ================================================================
def merge_results(rows_a: List[Dict], rows_b: List[Dict]) -> List[Dict]:
    merged = []
    max_len = max(len(rows_a), len(rows_b))

    for i in range(max_len):
        base = rows_a[i] if i < len(rows_a) else {}
        ind = rows_b[i] if i < len(rows_b) else {}

        merged.append({**base, **ind})

    return merged


# ================================================================
# PROCESS ONE CHUNK (Sequential)
# ================================================================
def process_chunk(chunk: str, index: int) -> List[Dict]:
    print(f"Processing chunk {index}…")

    rows_a = call_llm(PROMPT_A, chunk)
    rows_b = call_llm(PROMPT_B, chunk)

    combined = merge_results(rows_a, rows_b)

    # store order
    for r in combined:
        r["_chunk_index"] = index

    print(f"Chunk {index}: {len(combined)} rows extracted")
    return combined


# ================================================================
# PROCESS ENTIRE DOCUMENT (SEQUENTIAL)
# ================================================================
def process_document(full_text: str) -> List[Dict]:
    chunks = split_text(full_text)
    print(f"Total chunks: {len(chunks)}")

    all_rows = []

    for i, chunk in enumerate(chunks):
        rows = process_chunk(chunk, i)
        all_rows.extend(rows)

    # Sort by chunk index
    all_rows.sort(key=lambda x: x["_chunk_index"])
    return all_rows


# ================================================================
# MAIN ENTRYPOINT
# ================================================================
if __name__ == "__main__":
    input_file = "input_text.txt"

    if not os.path.exists(input_file):
        raise FileNotFoundError("Place your contract text in input_text.txt")

    # Load file
    with open(input_file, "r", encoding="utf-8") as f:
        text = f.read()

    # Process entire document
    rows = process_document(text)

    print("Total final rows:", len(rows))

    # Convert to DataFrame
    df = pd.DataFrame(rows)

    # Print final dataframe
    display(df)  # Databricks-friendly
