import cv2
import numpy as np
from pdf2image import convert_from_path
import os
import gc
from concurrent.futures import ThreadPoolExecutor, as_completed

def preprocess_image(image):
    """Preprocess image for analysis with memory efficiency"""
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray = image
    
    # Memory-efficient adaptive thresholding
    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                  cv2.THRESH_BINARY_INV, 11, 2)
    
    # Clean small noise with minimal memory usage
    kernel = np.ones((2, 2), np.uint8)
    cleaned = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)
    
    del gray, thresh
    return cleaned

def safe_swt(gray_img):
    """Memory-safe Stroke Width Transform implementation"""
    try:
        edges = cv2.Canny(gray_img, 50, 150)
        gradients_x = cv2.Sobel(gray_img, cv2.CV_32F, 1, 0, ksize=3)
        gradients_y = cv2.Sobel(gray_img, cv2.CV_32F, 0, 1, ksize=3)
        
        swt = np.zeros(gray_img.shape, dtype=np.float32)
        edge_points = np.argwhere(edges > 0)
        
        # Process edges in chunks
        chunk_size = 10000
        for i in range(0, len(edge_points), chunk_size):
            chunk = edge_points[i:i + chunk_size]
            for x, y in chunk:
                ray = []
                step_x = gradients_x[x, y]
                step_y = gradients_y[x, y]
                
                mag = max(1e-7, np.sqrt(step_x**2 + step_y**2))
                step_x /= mag
                step_y /= mag
                
                prev_x, prev_y = x, y
                for _ in range(100):  # Limit ray length
                    curr_x = int(prev_x + step_x)
                    curr_y = int(prev_y + step_y)
                    
                    if not (0 <= curr_x < edges.shape[0] and 0 <= curr_y < edges.shape[1]):
                        break
                        
                    ray.append((curr_x, curr_y))
                    
                    if edges[curr_x, curr_y] > 0:
                        opp_x = -gradients_x[curr_x, curr_y]
                        opp_y = -gradients_y[curr_x, curr_y]
                        mag_opp = max(1e-7, np.sqrt(opp_x**2 + opp_y**2))
                        
                        if (step_x * (opp_x/mag_opp) + step_y * (opp_y/mag_opp)) < -0.5:
                            length = np.sqrt((curr_x - x)**2 + (curr_y - y)**2)
                            for rx, ry in ray:
                                swt[rx, ry] = length
                        break
                        
                    prev_x, prev_y = curr_x, curr_y
        
        return swt
    except Exception as e:
        print(f"SWT error: {str(e)}")
        return np.zeros(gray_img.shape, dtype=np.float32)

def analyze_contours(img, min_area=25):
    """Memory-efficient contour analysis"""
    try:
        preprocessed = preprocess_image(img)
        contours, _ = cv2.findContours(preprocessed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        features = {
            'irregularity': [],
            'aspect_ratio': [],
            'solidity': []
        }
        
        for cnt in contours:
            area = cv2.contourArea(cnt)
            if area < min_area:
                continue
                
            perimeter = cv2.arcLength(cnt, True)
            
            # Irregularity
            if perimeter > 0 and area > 0:
                features['irregularity'].append((perimeter ** 2) / (4 * np.pi * area))
            
            # Aspect ratio
            _, _, w, h = cv2.boundingRect(cnt)
            if h > 0:
                features['aspect_ratio'].append(w / h)
            
            # Solidity
            hull = cv2.convexHull(cnt)
            hull_area = cv2.contourArea(hull)
            if hull_area > 0:
                features['solidity'].append(area / hull_area)
        
        # Calculate averages
        avg_features = {}
        for key in features:
            if features[key]:
                avg_features[key] = np.mean(features[key])
            else:
                avg_features[key] = 1.0  # Neutral value
        
        return avg_features
    except Exception as e:
        print(f"Contour error: {str(e)}")
        return {'irregularity': 1.0, 'aspect_ratio': 1.0, 'solidity': 1.0}

def process_page(page_img, page_num):
    """Process a single page with memory safety"""
    try:
        # Convert and downscale
        img = cv2.cvtColor(np.array(page_img), cv2.COLOR_RGB2BGR)
        h, w = img.shape[:2]
        scale = min(1.0, 1024 / max(h, w))
        if scale < 1.0:
            img = cv2.resize(img, (int(w * scale), int(h * scale)))
        
        # Convert to grayscale for SWT
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        
        # Get features
        swt = safe_swt(gray)
        nonzero_swt = swt[swt > 0]
        
        if len(nonzero_swt) > 0:
            sw_cv = np.std(nonzero_swt) / np.mean(nonzero_swt)
        else:
            sw_cv = 0
        
        contour_features = analyze_contours(img)
        
        # Calculate confidence
        sw_confidence = min(1.0, sw_cv * 1.5)
        contour_confidence = min(1.0, 
            (contour_features['irregularity'] - 1) * 0.3 + 
            (1 - contour_features['solidity']) * 0.7)
        
        combined_confidence = (sw_confidence * 0.6 + contour_confidence * 0.4)
        
        # Clean up
        del img, gray, swt, nonzero_swt
        gc.collect()
        
        return {
            'page': page_num,
            'confidence': combined_confidence,
            'has_handwriting': combined_confidence > 0.5,
            'sw_cv': sw_cv,
            'contour_features': contour_features
        }
    except Exception as e:
        print(f"Error processing page {page_num}: {str(e)}")
        return {
            'page': page_num,
            'error': str(e),
            'has_handwriting': False,
            'confidence': 0
        }

def pdf_has_handwriting(pdf_path, pages_to_check=None, max_workers=2):
    """Main function to detect handwriting in PDF with memory management"""
    results = []
    has_handwriting = False
    
    try:
        # Get page count if not specified
        if pages_to_check is None:
            from PyPDF2 import PdfReader
            with open(pdf_path, 'rb') as f:
                pages_to_check = len(PdfReader(f).pages)
        
        # Process in batches to avoid memory overload
        batch_size = min(5, pages_to_check)
        for batch_start in range(0, pages_to_check, batch_size):
            batch_end = min(batch_start + batch_size, pages_to_check)
            
            # Convert batch of pages with reduced DPI
            pages = convert_from_path(
                pdf_path,
                first_page=batch_start + 1,
                last_page=batch_end,
                dpi=200,
                thread_count=1,
                fmt='jpeg'
            )
            
            # Process pages with thread pool (limited threads for memory)
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                futures = [
                    executor.submit(process_page, page, batch_start + i + 1)
                    for i, page in enumerate(pages)
                ]
                
                for future in as_completed(futures):
                    result = future.result()
                    results.append(result)
                    if result.get('has_handwriting', False):
                        has_handwriting = True
            
            # Explicit cleanup
            del pages
            gc.collect()
    
    except Exception as e:
        print(f"PDF processing error: {str(e)}")
        return False, [{'error': str(e)}]
    
    return has_handwriting, results

if __name__ == "__main__":
    # Directly specify your PDF path here
    pdf_path = "sample.pdf"  # Replace with your PDF file path
    pages_to_check = 5       # Set to None to check all pages
    output_dir = "results"   # Set to None to skip saving results
    
    print(f"Analyzing PDF: {pdf_path}")
    has_hw, results = pdf_has_handwriting(
        pdf_path,
        pages_to_check=pages_to_check
    )
    
    print(f"\nFinal Result: {'HAS HANDWRITING' if has_hw else 'No handwriting detected'}")
    print("\nPage Details:")
    for res in results:
        if 'error' in res:
            print(f"Page {res.get('page', '?')}: ERROR - {res['error']}")
        else:
            print(f"Page {res['page']}: Confidence = {res['confidence']:.2f} - {'Handwriting' if res['has_handwriting'] else 'Printed'}")

    if output_dir:
        os.makedirs(output_dir, exist_ok=True)
        with open(os.path.join(output_dir, "results.json"), "w") as f:
            import json
            json.dump({
                "has_handwriting": has_hw,
                "page_results": results
            }, f, indent=2)
