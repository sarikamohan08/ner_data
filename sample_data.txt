import openai
import json

# ========== CONFIGURATION ==========
openai.api_key = "your-openai-api-key"  # <-- Replace with your OpenAI API key
TXT_FILE_PATH = "your_text_file.txt"    # <-- Replace with your actual file path
OUTPUT_JSON_PATH = "embeddings.json"    # Where to save the result
WORDS_PER_CHUNK = 200                   # Adjust as needed (safe for OpenAI models)
EMBEDDING_MODEL = "text-embedding-3-small"
# ===================================

# 1. Load the text file
def load_text(file_path):
    with open(file_path, 'r', encoding='utf-8') as f:
        return f.read().replace('\n', ' ').strip()

# 2. Split text into chunks
def chunk_text(text, max_words=200):
    words = text.split()
    return [' '.join(words[i:i + max_words]) for i in range(0, len(words), max_words)]

# 3. Get OpenAI embeddings (batched)
def get_embeddings(chunks):
    response = openai.Embedding.create(
        input=chunks,
        model=EMBEDDING_MODEL
    )
    return [item['embedding'] for item in response['data']]

# 4. Save embeddings to a JSON file
def save_embeddings(embeddings, out_path):
    with open(out_path, "w") as f:
        json.dump(embeddings, f)

# 5. Main flow
def main():
    print("📄 Loading text...")
    text = load_text(TXT_FILE_PATH)

    print("✂️  Chunking text...")
    chunks = chunk_text(text, WORDS_PER_CHUNK)
    print(f"🔹 Total chunks: {len(chunks)}")

    print("📡 Sending to OpenAI for embeddings...")
    embeddings = get_embeddings(chunks)

    print(f"💾 Saving {len(embeddings)} embeddings to {OUTPUT_JSON_PATH}")
    save_embeddings(embeddings, OUTPUT_JSON_PATH)
    print("✅ Done!")

if __name__ == "__main__":
    main()
