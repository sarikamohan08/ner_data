import openai
from pdf2image import convert_from_path
import io
from PIL import Image
import base64

openai.api_key = "YOUR_OPENAI_API_KEY"

# Convert PDF to images (one image per page)
def pdf_to_images(pdf_path):
    return convert_from_path(pdf_path)

# Convert PIL image to base64 string
def image_to_base64(image):
    buffered = io.BytesIO()
    image.save(buffered, format="PNG")
    return base64.b64encode(buffered.getvalue()).decode("utf-8")

# Extract both text and tables from an image using GPT-4o
def extract_text_and_tables_from_image(image):
    base64_image = image_to_base64(image)
    response = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "You're a document analyst. Extract all useful content, especially structured tables, from scanned images."},
            {
                "role": "user",
                "content": [
                    {
                        "type": "image_url",
                        "image_url": {"url": f"data:image/png;base64,{base64_image}"},
                    },
                    {
                        "type": "text",
                        "text": (
                            "Please extract all important information from this document page. "
                            "If there are any tables, extract them as structured data in Markdown or JSON. "
                            "Also include key-value pairs and labeled information if available."
                        )
                    }
                ],
            },
        ],
    )
    return response.choices[0].message.content.strip()

# Extract all pages
def extract_all_pages(pdf_path):
    images = pdf_to_images(pdf_path)
    chunks = []
    for i, image in enumerate(images):
        print(f"Extracting content from page {i+1}...")
        extracted = extract_text_and_tables_from_image(image)
        chunks.append(extracted)
    return chunks

# RAG-style question-answering
def rag_ask_question(chunks, question):
    context = "\n\n---\n\n".join(chunks)
    prompt = f"""Use the following extracted document content to answer the question.

DOCUMENT:
{context}

QUESTION:
{question}
"""
    response = openai.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}]
    )
    return response.choices[0].message.content.strip()

# === Example Usage ===
pdf_path = "scanned_with_tables.pdf"
chunks = extract_all_pages(pdf_path)

# Ask any question, tables will be part of the context
question = "What is the Effective Date? Also, summarize any tabular data."
answer = rag_ask_question(chunks, question)

print("\nâœ… Final Answer:\n", answer)
